{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkqcKK-Ed1DM",
        "outputId": "6021df03-2f91-4d37-eeb9-76c4a1a8b3ea"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "txmPIxl2ujXu",
        "outputId": "6203df9c-68b9-4a6b-b56a-bd20ca92b035"
      },
      "outputs": [],
      "source": [
        "from snowflake.snowpark.session import Session\n",
        "import snowflake.snowpark.functions as F\n",
        "import snowflake.snowpark.types as T\n",
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaimrGDFusF9"
      },
      "outputs": [],
      "source": [
        "with open('/Users/anshikabajpai/Desktop/github_adt_project/kidney-diagnosis-snowflake/creds.json') as f:\n",
        "    connection_parameters = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-dRW4oAvKkO"
      },
      "outputs": [],
      "source": [
        "session = Session.builder.configs(connection_parameters).create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t3TvfBUvQfL",
        "outputId": "e5d0fb04-6765-4c8e-b3d8-2733bb866b3b"
      },
      "outputs": [],
      "source": [
        "session.sql(\"CREATE OR REPLACE WAREHOUSE HOL_WH WITH WAREHOUSE_SIZE='X-SMALL'\").collect()\n",
        "session.sql(\"CREATE OR REPLACE DATABASE KIDNEY_DB\").collect()\n",
        "session.sql(\"CREATE OR REPLACE SCHEMA DATA\").collect() # one scpecific schema for training and inference data\n",
        "session.sql(\"use schema PUBLIC\").collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0jqnIZlvXGi",
        "outputId": "dd684d47-0345-400b-996d-9f0a0210ed56"
      },
      "outputs": [],
      "source": [
        "session.sql('select current_warehouse(), current_database(), current_schema(), current_user(), current_role()').collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ArZBCzmvfOL",
        "outputId": "b1b0a760-c527-4e7f-9c40-441396b5fe3f"
      },
      "outputs": [],
      "source": [
        "session.sql(\"create or replace stage load_data\").collect()\n",
        "session.sql(\"create or replace stage models\").collect()\n",
        "\n",
        "session.sql(\"create or replace stage procedures\").collect()\n",
        "session.sql(\"create or replace stage custom_packages\").collect()\n",
        "\n",
        "session.sql(\"create or replace sequence seq_model_01 start = 1 increment = 1\").collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHqaJDsMvM2d",
        "outputId": "7193b062-986d-45fa-b641-9092bae389bd"
      },
      "outputs": [],
      "source": [
        "session.file.put('/Users/anshikabajpai/Desktop/github_adt_project/kidney-diagnosis-snowflake/preprocessing/kidney_disease_train.csv', 'LOAD_DATA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8sjS6eu3kpk"
      },
      "outputs": [],
      "source": [
        "schema_log=T.StructType([T.StructField(\"date\", T.TimestampType()),\n",
        "                     T.StructField(\"class_method\", T.StringType()),\n",
        "                     T.StructField(\"model_name\", T.StringType()),\n",
        "                     T.StructField(\"data_training\", T.StringType()),\n",
        "                     T.StructField(\"class_report\", T.VariantType()),\n",
        "                     T.StructField(\"TN\", T.IntegerType()),\n",
        "                     T.StructField(\"FP\", T.IntegerType()),\n",
        "                     T.StructField(\"FN\", T.IntegerType()),\n",
        "                     T.StructField(\"TP\", T.IntegerType()),\n",
        "                     T.StructField(\"roc_auc\", T.FloatType()),\n",
        "                     T.StructField(\"avg_precision\", T.FloatType()),\n",
        "\n",
        "])\n",
        "\n",
        "log_df = session.create_dataframe([],schema=schema_log)\n",
        "log_df.write.mode('overwrite').save_as_table('Models_Eval')\n",
        "\n",
        "schema_inference=T.StructType([T.StructField(\"date\", T.TimestampType()),\n",
        "                     T.StructField(\"model_name\", T.StringType()),\n",
        "                     T.StructField(\"source_table\", T.StringType()),\n",
        "                     T.StructField(\"target_table\", T.StringType()),\n",
        "                     T.StructField(\"accuracy\", T.FloatType()),\n",
        "                     T.StructField(\"precision\", T.FloatType()),\n",
        "                     T.StructField(\"recall\", T.FloatType()),\n",
        "                     T.StructField(\"f1_score\", T.FloatType()),\n",
        "                     T.StructField(\"TN\", T.IntegerType()),\n",
        "                     T.StructField(\"FP\", T.IntegerType()),\n",
        "                     T.StructField(\"FN\", T.IntegerType()),\n",
        "                     T.StructField(\"TP\", T.IntegerType()),\n",
        "                     T.StructField(\"Time_Total\", T.FloatType()),\n",
        "                     T.StructField(\"Time_Scoring\", T.FloatType())\n",
        "])\n",
        "\n",
        "inference_df = session.create_dataframe([],schema=schema_inference)\n",
        "inference_df.write.mode('overwrite').save_as_table('Inference_Info')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVvgJLkP4Pr4",
        "outputId": "3130c1a3-379b-44c0-f9d5-0ac2fe168939"
      },
      "outputs": [],
      "source": [
        "session.sql(\"create or replace view accuracy_sum_v as select DATE, model_name, class_method, data_training,\\\n",
        "        class_report:accuracy as accuracy, roc_auc, avg_precision from Models_Eval;\").collect()\n",
        "\n",
        "\n",
        "cmd = \"\"\"create or replace view class_report_sumary_v as\\\n",
        "            select model_name,  data_training,\\\n",
        "            class_report:\"0\".\"f1-score\" neg_f1_score,\\\n",
        "            class_report:\"0\".\"precision\" neg_precision,\\\n",
        "            class_report:\"0\".\"recall\" neg_recall,\\\n",
        "            class_report:\"1\".\"f1-score\" pos_f1_score,\\\n",
        "            class_report:\"1\".\"precision\" pos_precision,\\\n",
        "            class_report:\"1\".\"recall\" pos_recall,\\\n",
        "            class_report:\"accuracy\" accuracy,\\\n",
        "            TN, FP, FN, TP  from Models_Eval\"\"\"\n",
        "session.sql(cmd).collect()\n",
        "\n",
        "session.sql(\"create or replace view data_training_v as select model_name, data_training from Models_Eval\").collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvTCW7pXnomo"
      },
      "outputs": [],
      "source": [
        "schema_model = T.StructType([T.StructField(\"model_name\", T.StringType())])\n",
        "\n",
        "df_models_table = session.create_dataframe([\n",
        "                         ['Logistic Regression'],\n",
        "                         ['Naive Bayes'],\n",
        "                         ['Random Forest Classifier'],\n",
        "                         ['DecisionTreeClassifier'],\n",
        "                         ['Support Vector Classifier'],\n",
        "                        #  ['XGBoost'],\n",
        "                         ['K_NeighborsClassifier']], schema=schema_model)\n",
        "\n",
        "df_models_table.write.mode(\"overwrite\").save_as_table(\"MODELS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqiHHGx5opVG"
      },
      "outputs": [],
      "source": [
        "def copy_into (session: Session, file_name: str, table_name: str) -> str:\n",
        "    import snowflake.snowpark.types as T\n",
        "\n",
        "    schema_kidney = T.StructType([\n",
        "        # T.StructField(\"id\", T.DoubleType()),\n",
        "        T.StructField(\"age\", T.DoubleType()),\n",
        "        T.StructField(\"bp\", T.DoubleType()),\n",
        "        T.StructField(\"sg\", T.DoubleType()),\n",
        "        T.StructField(\"al\", T.DoubleType()),\n",
        "        T.StructField(\"su\", T.DoubleType()),\n",
        "        T.StructField(\"rbc\", T.IntegerType()),\n",
        "        T.StructField(\"pc\", T.IntegerType()),\n",
        "        T.StructField(\"pcc\", T.IntegerType()),\n",
        "        T.StructField(\"ba\", T.IntegerType()),\n",
        "        T.StructField(\"bgr\", T.DoubleType()),\n",
        "        T.StructField(\"bu\", T.DoubleType()),\n",
        "        T.StructField(\"sc\", T.DoubleType()),\n",
        "        T.StructField(\"sod\", T.DoubleType()),\n",
        "        T.StructField(\"pot\", T.DoubleType()),\n",
        "        T.StructField(\"hemo\", T.DoubleType()),\n",
        "        T.StructField(\"pcv\", T.DoubleType()),\n",
        "        T.StructField(\"wc\", T.DoubleType()),\n",
        "        T.StructField(\"rc\", T.DoubleType()),\n",
        "        T.StructField(\"htn\", T.IntegerType()),\n",
        "        T.StructField(\"dm\", T.StringType()),\n",
        "        T.StructField(\"cad\", T.StringType()),\n",
        "        T.StructField(\"appet\", T.IntegerType()),\n",
        "        T.StructField(\"pe\", T.IntegerType()),\n",
        "        T.StructField(\"ane\", T.IntegerType()),\n",
        "        T.StructField(\"classification\", T.StringType())\n",
        "])\n",
        "\n",
        "    # Load the table within the DATA schema\n",
        "    load_df2 = session.read\\\n",
        "        .option(\"FIELD_DELIMITER\", ',')\\\n",
        "        .option(\"SKIP_HEADER\", 1)\\\n",
        "        .option(\"ON_ERROR\", \"CONTINUE\")\\\n",
        "        .schema(schema_kidney).csv(file_name)\\\n",
        "        .copy_into_table(table_name)\n",
        "\n",
        "    return load_df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV80M97io7hU",
        "outputId": "d7f382d6-7374-49ab-8cd5-76e5225f31a8"
      },
      "outputs": [],
      "source": [
        "copy_into(session, \"@LOAD_DATA/kidney_disease_train.csv\", \"TEST_TABLE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NkFnjWD8bMP"
      },
      "outputs": [],
      "source": [
        "# session.sql(\"DROP TABLE IF EXISTS DEFAULT\").collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BO6Jgq9p7vc",
        "outputId": "7f43a998-e037-434b-d69a-19fb59adf11c"
      },
      "outputs": [],
      "source": [
        "session.use_warehouse(\"HOL_WH\")\n",
        "\n",
        "session.sproc.register(\n",
        "    func=copy_into,\n",
        "    name=\"copy_into\",\n",
        "    packages=['snowflake-snowpark-python'],\n",
        "    is_permanent=True,\n",
        "    stage_location=\"@procedures\",\n",
        "    replace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkSSL_7Dqmcr"
      },
      "outputs": [],
      "source": [
        "import cloudpickle\n",
        "import os\n",
        "\n",
        "def save_file_to_stage(session, obj, stage, name):\n",
        "    model_output_dir = '/tmp'\n",
        "    os.makedirs(model_output_dir, exist_ok=True)\n",
        "    model_file = os.path.join(model_output_dir, name)\n",
        "\n",
        "    # Save the object with cloudpickle\n",
        "    with open(model_file, 'wb') as f:\n",
        "        cloudpickle.dump(obj, f)\n",
        "\n",
        "    # Upload to the specified Snowflake stage\n",
        "    session.file.put(model_file, stage, overwrite=True, auto_compress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DZ4-IwmsRKA"
      },
      "outputs": [],
      "source": [
        "# Function to deploy a trained model as a UDF, used by the training stored procedure\n",
        "def create_udf(snf_session, udf_name, model, input_cols, stage_loc, py_packages):\n",
        "    @F.udf(name=udf_name, is_permanent=True, stage_location=stage_loc, max_batch_size=1000,\n",
        "           packages=py_packages, replace=True, session=snf_session)\n",
        "    def predict(ds: T.PandasSeries[dict]) -> T.PandasSeries[float]:\n",
        "        df = pd.json_normalize(ds)[input_cols]\n",
        "        prediction = model.predict(df)\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQcOiMgzs3Gl"
      },
      "outputs": [],
      "source": [
        "def log_training(session, class_method, model_name, clone_table_name, class_report, TN, FP, FN, TP,\n",
        "                     auc, ave_precision):\n",
        "    import datetime\n",
        "    import json\n",
        "\n",
        "    dt = datetime.datetime.now()\n",
        "    dt_str = str(dt)\n",
        "\n",
        "    cmd = \"INSERT INTO models_eval (select '%s', '%s', '%s', '%s', PARSE_JSON('%s'),\\\n",
        "                        '%s','%s','%s','%s','%s','%s')\" %\\\n",
        "        (dt_str, class_method, model_name, clone_table_name, json.dumps(class_report),\\\n",
        "         TN, FP, FN, TP, auc, ave_precision)\n",
        "\n",
        "    session.sql(cmd).collect()\n",
        "\n",
        "def log_inference_snp(model_name, source_table, target_table, metrics_df, time_total, time_inference):\n",
        "\n",
        "    lg_df = metrics_df.with_columns([\"date\", \"model_name\", \"source_table\", \"target_table\", \"Time_Total\", \"Time_Scoring\"]\n",
        "                                    , [F.current_timestamp(), F.lit(model_name), F.lit(source_table), F.lit(target_table), F.lit(time_total), F.lit(time_inference)])\n",
        "\n",
        "    lg_df.write.save_as_table(\"INFERENCE_RUNS\", mode=\"append\", column_order=\"name\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sf_train(session: Session, class_method: str, table_name: str,\n",
        "             stage: str, model_name: str, keep_data_clone: bool) -> dict:\n",
        "    \"\"\"\n",
        "    Train a classification model on a Snowflake table using scikit-learn .\n",
        "    Works locally (no snowflake.snowpark.ml dependency).\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Imports ---\n",
        "    from snowflake.snowpark import functions as F\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    from sklearn.metrics import (\n",
        "        confusion_matrix, classification_report,\n",
        "        roc_auc_score, average_precision_score,\n",
        "        precision_recall_curve, roc_curve\n",
        "    )\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import json\n",
        "\n",
        "    # --- Helpers (assumed defined elsewhere) ---\n",
        "    # save_file_to_stage(session, model_obj, stage, file_name)\n",
        "    # create_udf(session, model_name, model_obj, input_cols, stage_loc, py_packages)\n",
        "    # log_training(session, class_method, model_name, data_table, metrics...)\n",
        "    \n",
        "    # --- Step 1: Unique model name ---\n",
        "    seq = str(session.sql(\"select seq_model_01.nextval\").collect()[0][0])\n",
        "    model_name = model_name + \"_\" + seq\n",
        "\n",
        "    # --- Step 2: Clone table if required ---\n",
        "    if keep_data_clone:\n",
        "        clone_table_name = f\"{table_name}_CLONE_{model_name}\"\n",
        "        session.sql(f\"create TABLE {clone_table_name} clone {table_name}\").collect()\n",
        "    else:\n",
        "        clone_table_name = table_name\n",
        "\n",
        "    # --- Step 3: Load data ---\n",
        "    df_sf = session.table(clone_table_name)\n",
        "\n",
        "    # Get all column names\n",
        "    cols = df_sf.columns\n",
        "    if \"CLASSIFICATION\" not in [c.upper() for c in cols]:\n",
        "        raise ValueError(\"Target column 'CLASSIFICATION' not found in table\")\n",
        "\n",
        "    # Identify target and feature columns\n",
        "    target_col = [c for c in cols if c.upper() == \"CLASSIFICATION\"][0]\n",
        "    feature_cols = [c for c in cols if c != target_col]\n",
        "\n",
        "    # Convert Snowpark DataFrame to Pandas\n",
        "    pdf = df_sf.to_pandas()\n",
        "\n",
        "    # Separate features and target\n",
        "    X = pdf[feature_cols]\n",
        "    y = pdf[target_col].astype(int)\n",
        "\n",
        "    # --- Step 4: Preprocessing (scaling) ---\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_scaled = pd.DataFrame(X_scaled, columns=feature_cols)\n",
        "\n",
        "    # Save scaler to stage\n",
        "    scaler_name = model_name + \".scaler\"\n",
        "    save_file_to_stage(session, scaler, stage, scaler_name)\n",
        "\n",
        "    # --- Step 5: Choose classifier ---\n",
        "    if class_method == \"Logistic Regression\":\n",
        "        model = LogisticRegression()\n",
        "    elif class_method == \"Naive Bayes\":\n",
        "        model = GaussianNB()\n",
        "    elif class_method == \"Random Forest Classifier\":\n",
        "        model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=8)\n",
        "    elif class_method == \"K_NeighborsClassifier\":\n",
        "        model = KNeighborsClassifier(n_neighbors=5)\n",
        "    elif class_method == \"Support Vector Classifier\":\n",
        "        model = SVC(kernel='rbf', C=2, probability=True)\n",
        "    elif class_method == \"DecisionTreeClassifier\":\n",
        "        model = DecisionTreeClassifier(criterion='entropy', random_state=42, max_depth=6)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown classifier: {class_method}\")\n",
        "\n",
        "    # --- Step 6: Train using the entire dataset ---\n",
        "    model.fit(X_scaled, y)\n",
        "\n",
        "    # --- Step 7: Predictions (on same dataset, since using full data) ---\n",
        "    y_pred = model.predict(X_scaled)\n",
        "\n",
        "    # --- Step 8: Save model and create UDF ---\n",
        "    save_file_to_stage(session, model, stage, model_name)\n",
        "    input_cols = X_scaled.columns\n",
        "    stage_loc = 'procedures'\n",
        "    py_packages = ['pandas==1.5.3', 'numpy==1.23.5', 'scikit-learn==1.2.2']\n",
        "    create_udf(session, model_name, model, input_cols, stage_loc, py_packages)\n",
        "\n",
        "    # --- Step 9: Metrics ---\n",
        "    cnf_matrix = confusion_matrix(y, y_pred)\n",
        "    TN, FP, FN, TP = cnf_matrix.ravel()\n",
        "    class_report = classification_report(y, y_pred, output_dict=True)\n",
        "    acc_score = class_report[\"accuracy\"] * 100\n",
        "    fpr, tpr, _ = roc_curve(y, y_pred)\n",
        "    auc = roc_auc_score(y, y_pred)\n",
        "    p, r, _ = precision_recall_curve(y, y_pred)\n",
        "    ave_precision = average_precision_score(y, y_pred)\n",
        "\n",
        "    # Log training results in Snowflake\n",
        "    log_training(session, class_method, model_name, clone_table_name, class_report,\n",
        "                 TN, FP, FN, TP, auc, ave_precision)\n",
        "\n",
        "    # --- Step 10: Return summary ---\n",
        "    ret_dict = {\n",
        "        \"Model\": model_name,\n",
        "        \"Classifier\": class_method,\n",
        "        \"Confusion_Matrix\": cnf_matrix.tolist(),\n",
        "        \"Accuracy(%)\": acc_score,\n",
        "        \"Classification_Report\": class_report,\n",
        "        \"FPR\": fpr.tolist(),\n",
        "        \"TPR\": tpr.tolist(),\n",
        "        \"Precision\": p.tolist(),\n",
        "        \"Recall\": r.tolist(),\n",
        "        \"AUC\": auc,\n",
        "        \"Average_Precision\": ave_precision\n",
        "    }\n",
        "\n",
        "    return ret_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz1Y6sUZ7b-t",
        "outputId": "161bb9ca-6f0e-450a-ed9b-5fb013c3d680"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "\n",
        "ret = sf_train(session, class_method=\"Logistic Regression\", table_name=\"TEST_TABLE\",\n",
        "         stage=\"@models\", model_name=\"LR\", keep_data_clone=False)\n",
        "print (ret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdWAOcDVMGD8",
        "outputId": "04611fea-d8a1-4e76-dcc1-ceeaa49c3eed"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "ret = sf_train(session, class_method=\"Naive Bayes\", table_name=\"TEST_TABLE\",\n",
        "         stage=\"@models\", model_name=\"NB\", keep_data_clone=False)\n",
        "print (ret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbNlUeARMP2j",
        "outputId": "dcf1ac83-cb7f-4d3f-904c-2aba4994033d"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "ret = sf_train(session, class_method=\"Random Forest Classifier\", table_name=\"TEST_TABLE\",\n",
        "         stage=\"@models\", model_name=\"RF\", keep_data_clone=False)\n",
        "print (ret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b10eparPMRlK",
        "outputId": "25ef0658-2e88-4d6d-c542-0d94b2a4c2a9"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "ret = sf_train(session, class_method=\"K_NeighborsClassifier\", table_name=\"TEST_TABLE\",\n",
        "         stage=\"@models\", model_name=\"KNN\", keep_data_clone=False)\n",
        "print (ret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbN0igWpMR70",
        "outputId": "2fe3ce9c-2258-4a3c-9bcc-6ad40038d65b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "ret = sf_train(session, class_method=\"Support Vector Classifier\", table_name=\"TEST_TABLE\",\n",
        "         stage=\"@models\", model_name=\"SVC\", keep_data_clone=False)\n",
        "print (ret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2jpXyvkMSPG",
        "outputId": "e49a790d-3c50-4db3-c611-2391cda414d4"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "ret = sf_train(session, class_method=\"DecisionTreeClassifier\", table_name=\"TEST_TABLE\",\n",
        "         stage=\"@models\", model_name=\"DT\", keep_data_clone=False)\n",
        "print (ret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "laxsriULEzCz",
        "outputId": "298c26b7-d0b0-4de7-c41a-263b17251a24"
      },
      "outputs": [],
      "source": [
        "mc_df = session.table(\"MODELS_EVAL\")\n",
        "mc_df.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "tjGoTsN8F3E2",
        "outputId": "f42afc4c-ff5a-4036-8189-480747b2669c"
      },
      "outputs": [],
      "source": [
        "#For the last model, display ROC curve\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(ret[\"FPR\"], ret[\"TPR\"])\n",
        "plt.xlabel('fpr')\n",
        "plt.ylabel('tpr')\n",
        "plt.title(f'ROC Curve\\nROC AUC={ret[\"AUC\"]:.3f}');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "pnYyoqoXF7yR",
        "outputId": "b1aec376-f492-4874-b206-1bab9005a15c"
      },
      "outputs": [],
      "source": [
        "plt.plot(ret[\"Recall\"], ret[\"Precision\"])\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title(f'Precision Recal Curve\\nAP={ret[\"Average_Precision\"]:.3f}');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53WPxXYTGEsu",
        "outputId": "7e6ab655-c972-4028-89e5-3c78706c0160"
      },
      "outputs": [],
      "source": [
        "session.sproc.register(\n",
        "    func=sf_train,\n",
        "    name=\"sf_train\",\n",
        "    packages=['snowflake-snowpark-python',\n",
        "              'scikit-learn==1.2.2',\n",
        "              'cloudpickle==3.0.0',\n",
        "              'sqlalchemy==1.4.39',\n",
        "              'tqdm==4.64.1',\n",
        "              'colorlog==5.0.1','numpy==1.23.5','pandas==1.5.3']              ,\n",
        "\n",
        "    is_permanent=True,\n",
        "    stage_location=\"@procedures\",\n",
        "    replace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "yM9xSBsLGXtv",
        "outputId": "21bfae70-7822-408c-f72f-1e2f4ca9ec9d"
      },
      "outputs": [],
      "source": [
        "session.call (\"sf_train\", \"DecisionTreeClassifier\", \"TEST_TABLE\", \"@models\", \"DT\", True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skSFfgHhG2-0",
        "outputId": "710093e7-e291-485d-be6c-70caddac77bd"
      },
      "outputs": [],
      "source": [
        "session.sql(\"ls @models\").collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt8yzR8MtbaL"
      },
      "outputs": [],
      "source": [
        "# Function that calculates the metrics using Snowpark ie SQL\n",
        "def metrics_score_snp(df, y_true, y_pred):\n",
        "    return df.group_by([y_true, y_pred]).count()\\\n",
        "                .with_column(\"type\", F.when((F.col(y_true) == 0) & (F.col(y_pred) == 0), \"tn\")\\\n",
        "                                    .when((F.col(y_true) == 0) & (F.col(y_pred) == 1), \"fp\")\\\n",
        "                                    .when((F.col(y_true) == 1) & (F.col(y_pred) == 0), \"fn\")\\\n",
        "                                    .when((F.col(y_true) == 1) & (F.col(y_pred) == 1), \"tp\"))\\\n",
        "                .select([\"TYPE\", \"COUNT\"]).pivot(\"TYPE\", ['tn', 'tp', 'fn', 'fp']).sum(\"COUNT\")\\\n",
        "                .select(F.col(\"'tp'\").as_(\"tp\"), F.col(\"'tn'\").as_(\"tn\"), F.col(\"'fn'\").as_(\"fn\"), F.col(\"'fp'\").as_(\"fp\"))\\\n",
        "                .with_columns([\"accuracy\", \"precision\", \"recall\"],\n",
        "                             [((F.col(\"tp\") + F.col(\"tn\")) / (F.col(\"tp\") + F.col(\"tn\") + F.col(\"fn\") + F.col(\"fp\")))\n",
        "                             , (F.col(\"tp\") / (F.col(\"tp\") + F.col(\"fp\")))\n",
        "                              ,(F.col(\"tp\") / (F.col(\"tp\") + F.col(\"fn\")))])\\\n",
        "                .with_column(\"f1_score\", (F.lit(2)*F.col(\"precision\")*F.col(\"recall\")) / (F.col(\"precision\")+F.col(\"recall\")))\\\n",
        "                .select([\"ACCURACY\",\"PRECISION\", \"RECALL\",\"F1_SCORE\", \"TN\", \"FP\", \"FN\", \"TP\"])\n",
        "\n",
        "def sf_score(session: Session, table_name: str, table_target: str, stage: str,\n",
        "        model_name: str) -> dict:\n",
        "\n",
        "    import joblib\n",
        "    import time\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # This is the Snowpark Dataframe pointing to the table with the records we have to score\n",
        "    df = session.table(table_name)\n",
        "\n",
        "    #### Preprocessing ######\n",
        "\n",
        "    df_columns = df.drop(F.col('CLASSIFICATION'))\n",
        "    # df_columns.show()\n",
        "    df_pd = df_columns.to_pandas()  # Convert Snowpark DataFrame to Pandas\n",
        "\n",
        "    file_to_get = stage + \"/\" + model_name + \".scaler\"\n",
        "    session.file.get(file_to_get, '/tmp/')\n",
        "\n",
        "    scaler_name = \"/tmp/\" + model_name + \".scaler\"\n",
        "    scaler = joblib.load(scaler_name)\n",
        "    # print(scaler.feature_names_in_)\n",
        "\n",
        "    # Reorder columns to exactly match the scaler's feature order\n",
        "    df_pd = df_pd[scaler.feature_names_in_]\n",
        "    df_scaled = scaler.transform(df_pd)\n",
        "\n",
        "\n",
        "\n",
        "    ################\n",
        "    ## Predicting ##\n",
        "    ################\n",
        "\n",
        "    scaler_input_cols = df_pd.columns\n",
        "    scaler_output_cols = scaler_input_cols\n",
        "\n",
        "    ## Generate the column names we are goign to pass to the UDF\n",
        "    key_vals = []\n",
        "    for col in scaler_output_cols:\n",
        "        key_vals.extend([F.lit(col), F.col(col)])\n",
        "\n",
        "    # Taking time so we measure how much time spend predicting with UDFs\n",
        "    t1 = time.time()\n",
        "\n",
        "    df_scaled_pd = pd.DataFrame(df_scaled, columns=scaler.feature_names_in_)\n",
        "    # print(df_scaled_pd)\n",
        "\n",
        "    # Convert Pandas DataFrame to Snowpark DataFrame\n",
        "    try:\n",
        "        df_scaled_sp = session.create_dataframe(df_scaled_pd)\n",
        "        print(\"Snowpark dataframe successfully created!\")\n",
        "    except Exception as e:\n",
        "        print(\"Error creating Snowpark dataframe:\", e)\n",
        "        raise\n",
        "\n",
        "    y_true = df.select(F.col('CLASSIFICATION'))\n",
        "    y_true_pd=y_true.to_pandas()\n",
        "\n",
        "\n",
        "    results_df=session.create_dataframe(pd.concat([df_scaled_pd,y_true_pd],axis=1))\n",
        "\n",
        "    results_df = results_df.with_column(\"PREDICTED\", F.call_udf(model_name, F.object_construct(*key_vals)))\n",
        "\n",
        "    print(\"Columns in results_df:\", results_df.columns)\n",
        "    results_df.show(3)\n",
        "\n",
        "    t2 = time.time()\n",
        "\n",
        "\n",
        "    # get a new Snowpark Dataframe with the metrics score\n",
        "    df_metrics = metrics_score_snp(results_df, y_true=\"CLASSIFICATION\", y_pred=\"PREDICTED\")\n",
        "\n",
        "    results_df.write.mode(\"overwrite\").save_as_table(table_target)\n",
        "\n",
        "    # Get timestamps\n",
        "    t3 = time.time()\n",
        "    time_total = t3 - t0\n",
        "    time_inference = t2 - t1\n",
        "\n",
        "    # Write inference results into the INFERENCE_RUNS table\n",
        "    log_inference_snp(model_name, table_name, table_target, df_metrics, time_total, time_inference)\n",
        "\n",
        "    return df_metrics.collect()[0].as_dict() #accuracy, precision, recall, f1_score, TN, FP, FN, TP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvuZ0TKBNmq8",
        "outputId": "db10bb71-9f5d-4fc3-9095-33f12868dfe5"
      },
      "outputs": [],
      "source": [
        "sf_score(session, table_name=\"TEST_TABLE\", table_target=\"RESULTS_TABLE\", stage=\"@models\", model_name=\"LR_1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULl77rvHbMKu",
        "outputId": "aba3a386-a458-48b2-f651-cf8458213ce6"
      },
      "outputs": [],
      "source": [
        "session.sproc.register(\n",
        "    func=sf_score,\n",
        "    name=\"sf_score\",\n",
        "    packages=['snowflake-snowpark-python',\n",
        "              'scikit-learn==1.2.2',\n",
        "              'cloudpickle==3.0.0',\n",
        "              'sqlalchemy==1.4.39',\n",
        "              'tqdm==4.64.1',\n",
        "              'colorlog==5.0.1','numpy==1.23.5','pandas==1.5.3'],\n",
        "    is_permanent=True,\n",
        "    stage_location=\"@procedures\",\n",
        "    replace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "c2ZxMV4FbMN2",
        "outputId": "d79799d8-c0d6-414c-bab5-9a28bf1dad09"
      },
      "outputs": [],
      "source": [
        "df = session.table(\"INFERENCE_RUNS\")\n",
        "df.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "ioWq_ZWZbMQs",
        "outputId": "d179d225-bcc6-49c6-dbb5-81cde90ffaf5"
      },
      "outputs": [],
      "source": [
        "df = session.table(\"MODELS_EVAL\")\n",
        "df.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZNYjvyLZeCp"
      },
      "source": [
        "**Running the code on Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OVlI-0_Yv2p",
        "outputId": "73262814-c0b9-4c7d-ddbe-06707cea500a"
      },
      "outputs": [],
      "source": [
        "session.file.put('/Users/anshikabajpai/Desktop/github_adt_project/kidney-diagnosis-snowflake/preprocessing/kidney_disease_test.csv', 'LOAD_DATA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beEKbYTUX-S3",
        "outputId": "47772fad-1624-4288-9093-9501aea81a77"
      },
      "outputs": [],
      "source": [
        "print (session.call(\"copy_into\", \"@LOAD_DATA/kidney_disease_test.csv\", \"TEST2\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kheZBXeAYQ2H",
        "outputId": "039be23d-5c2e-40fc-ad76-2ef3770f91b5"
      },
      "outputs": [],
      "source": [
        "session.sql(\"ls @models\").collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQqD3o_lYVMP",
        "outputId": "57baae88-54f0-4af3-ab3b-9f49c2bcf308"
      },
      "outputs": [],
      "source": [
        "sf_score(session, table_name=\"TEST2\", table_target=\"RESULTS2\", stage=\"@models\", model_name=\"LR_1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "Du1szijuY5ST",
        "outputId": "17d89d12-f855-4f96-d75c-2fee3a879ced"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = session.table(\"RESULTS2\")\n",
        "df.limit(2).to_pandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POu1CfTA5zyQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
